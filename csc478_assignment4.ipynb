{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sojeong Yang<br>\n",
    "CSC 478 Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PCA for Reduced Dimensionality in Clustering\n",
    "\n",
    "<h3>a.</h3> \n",
    "\n",
    "**Load in the image data matrix, load in the numeric class labels from the segmentation class file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REGION-CENTROID-COL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REGION-CENTROID-ROW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REGION-PIXEL-COUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHORT-LINE-DENSITY-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHORT-LINE-DENSITY-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VEDGE-MEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VEDGE-SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HEDGE-MEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HEDGE-SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>INTENSITY-MEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RAWRED-MEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RAWBLUE-MEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RAWGREEN-MEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EXRED-MEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EXBLUE-MEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EXGREEN-MEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>VALUE-MEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SATURATION-MEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HUE-MEAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "0    REGION-CENTROID-COL\n",
       "1    REGION-CENTROID-ROW\n",
       "2     REGION-PIXEL-COUNT\n",
       "3   SHORT-LINE-DENSITY-5\n",
       "4   SHORT-LINE-DENSITY-2\n",
       "5             VEDGE-MEAN\n",
       "6               VEDGE-SD\n",
       "7             HEDGE-MEAN\n",
       "8               HEDGE-SD\n",
       "9         INTENSITY-MEAN\n",
       "10           RAWRED-MEAN\n",
       "11          RAWBLUE-MEAN\n",
       "12         RAWGREEN-MEAN\n",
       "13            EXRED-MEAN\n",
       "14           EXBLUE-MEAN\n",
       "15          EXGREEN-MEAN\n",
       "16            VALUE-MEAN\n",
       "17       SATURATION-MEAN\n",
       "18              HUE-MEAN"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 19 column names\n",
    "names = pd.read_csv('./segmentation_data/segmentation_names.txt', header=None)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>1.186342</td>\n",
       "      <td>12.925926</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>9.222222</td>\n",
       "      <td>18.666668</td>\n",
       "      <td>-6.111111</td>\n",
       "      <td>-11.111111</td>\n",
       "      <td>17.222221</td>\n",
       "      <td>18.666668</td>\n",
       "      <td>0.508139</td>\n",
       "      <td>1.910864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.720082</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>0.750309</td>\n",
       "      <td>13.740741</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>10.333334</td>\n",
       "      <td>19.222221</td>\n",
       "      <td>-6.222222</td>\n",
       "      <td>-10.222222</td>\n",
       "      <td>16.444445</td>\n",
       "      <td>19.222221</td>\n",
       "      <td>0.463329</td>\n",
       "      <td>1.941465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>225.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.388889</td>\n",
       "      <td>2.195113</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.520234</td>\n",
       "      <td>12.259259</td>\n",
       "      <td>10.333334</td>\n",
       "      <td>9.333334</td>\n",
       "      <td>17.111110</td>\n",
       "      <td>-5.777778</td>\n",
       "      <td>-8.777778</td>\n",
       "      <td>14.555555</td>\n",
       "      <td>17.111110</td>\n",
       "      <td>0.480149</td>\n",
       "      <td>1.987902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>1.254621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.894427</td>\n",
       "      <td>12.703704</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>18.111110</td>\n",
       "      <td>-5.111111</td>\n",
       "      <td>-11.111111</td>\n",
       "      <td>16.222221</td>\n",
       "      <td>18.111110</td>\n",
       "      <td>0.500966</td>\n",
       "      <td>1.875362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.691215</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.005540</td>\n",
       "      <td>15.592592</td>\n",
       "      <td>13.888889</td>\n",
       "      <td>11.777778</td>\n",
       "      <td>21.111110</td>\n",
       "      <td>-5.111111</td>\n",
       "      <td>-11.444445</td>\n",
       "      <td>16.555555</td>\n",
       "      <td>21.111110</td>\n",
       "      <td>0.442661</td>\n",
       "      <td>1.863654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>32.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944445</td>\n",
       "      <td>0.862963</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>7.962963</td>\n",
       "      <td>6.333334</td>\n",
       "      <td>11.888889</td>\n",
       "      <td>5.666666</td>\n",
       "      <td>-4.888889</td>\n",
       "      <td>11.777778</td>\n",
       "      <td>-6.888889</td>\n",
       "      <td>11.888889</td>\n",
       "      <td>0.520578</td>\n",
       "      <td>-1.982834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>8.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.611111</td>\n",
       "      <td>2.062962</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>8.370370</td>\n",
       "      <td>6.666666</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.444445</td>\n",
       "      <td>-5.111111</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>-5.777778</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.484805</td>\n",
       "      <td>-2.044946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>128.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555555</td>\n",
       "      <td>0.251852</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.162963</td>\n",
       "      <td>7.148148</td>\n",
       "      <td>5.555555</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-4.777778</td>\n",
       "      <td>11.222222</td>\n",
       "      <td>-6.444445</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>0.540918</td>\n",
       "      <td>-1.996307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>150.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.633334</td>\n",
       "      <td>1.388889</td>\n",
       "      <td>0.418518</td>\n",
       "      <td>8.444445</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.222222</td>\n",
       "      <td>6.111111</td>\n",
       "      <td>-4.333334</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>12.222222</td>\n",
       "      <td>0.503086</td>\n",
       "      <td>-1.943449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>124.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.388889</td>\n",
       "      <td>1.129630</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>10.037037</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.555555</td>\n",
       "      <td>7.555555</td>\n",
       "      <td>-6.111111</td>\n",
       "      <td>13.555555</td>\n",
       "      <td>-7.444445</td>\n",
       "      <td>14.555555</td>\n",
       "      <td>0.479931</td>\n",
       "      <td>-2.029312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2100 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1   2         3    4         5         6         7         8   \\\n",
       "0     110.0  189.0   9  0.000000  0.0  1.000000  0.666667  1.222222  1.186342   \n",
       "1      86.0  187.0   9  0.000000  0.0  1.111111  0.720082  1.444444  0.750309   \n",
       "2     225.0  244.0   9  0.000000  0.0  3.388889  2.195113  3.000000  1.520234   \n",
       "3      47.0  232.0   9  0.000000  0.0  1.277778  1.254621  1.000000  0.894427   \n",
       "4      97.0  186.0   9  0.000000  0.0  1.166667  0.691215  1.166667  1.005540   \n",
       "...     ...    ...  ..       ...  ...       ...       ...       ...       ...   \n",
       "2095   32.0  158.0   9  0.000000  0.0  0.944445  0.862963  0.833333  0.611111   \n",
       "2096    8.0  162.0   9  0.111111  0.0  1.611111  2.062962  0.333333  0.133333   \n",
       "2097  128.0  161.0   9  0.000000  0.0  0.555555  0.251852  0.777778  0.162963   \n",
       "2098  150.0  158.0   9  0.000000  0.0  2.166667  1.633334  1.388889  0.418518   \n",
       "2099  124.0  162.0   9  0.111111  0.0  1.388889  1.129630  2.000000  0.888889   \n",
       "\n",
       "             9          10         11         12        13         14  \\\n",
       "0     12.925926  10.888889   9.222222  18.666668 -6.111111 -11.111111   \n",
       "1     13.740741  11.666667  10.333334  19.222221 -6.222222 -10.222222   \n",
       "2     12.259259  10.333334   9.333334  17.111110 -5.777778  -8.777778   \n",
       "3     12.703704  11.000000   9.000000  18.111110 -5.111111 -11.111111   \n",
       "4     15.592592  13.888889  11.777778  21.111110 -5.111111 -11.444445   \n",
       "...         ...        ...        ...        ...       ...        ...   \n",
       "2095   7.962963   6.333334  11.888889   5.666666 -4.888889  11.777778   \n",
       "2096   8.370370   6.666666  12.000000   6.444445 -5.111111  10.888889   \n",
       "2097   7.148148   5.555555  10.888889   5.000000 -4.777778  11.222222   \n",
       "2098   8.444445   7.000000  12.222222   6.111111 -4.333334  11.333333   \n",
       "2099  10.037037   8.000000  14.555555   7.555555 -6.111111  13.555555   \n",
       "\n",
       "             15         16        17        18  \n",
       "0     17.222221  18.666668  0.508139  1.910864  \n",
       "1     16.444445  19.222221  0.463329  1.941465  \n",
       "2     14.555555  17.111110  0.480149  1.987902  \n",
       "3     16.222221  18.111110  0.500966  1.875362  \n",
       "4     16.555555  21.111110  0.442661  1.863654  \n",
       "...         ...        ...       ...       ...  \n",
       "2095  -6.888889  11.888889  0.520578 -1.982834  \n",
       "2096  -5.777778  12.000000  0.484805 -2.044946  \n",
       "2097  -6.444445  10.888889  0.540918 -1.996307  \n",
       "2098  -7.000000  12.222222  0.503086 -1.943449  \n",
       "2099  -7.444445  14.555555  0.479931 -2.029312  \n",
       "\n",
       "[2100 rows x 19 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data with (0-18) columns\n",
    "dt = pd.read_csv('./segmentation_data/segmentation_data.txt', header=None)\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GRASS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRASS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRASS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRASS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GRASS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>CEMENT</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>CEMENT</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>CEMENT</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>CEMENT</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>CEMENT</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  1\n",
       "0      GRASS  0\n",
       "1      GRASS  0\n",
       "2      GRASS  0\n",
       "3      GRASS  0\n",
       "4      GRASS  0\n",
       "...      ... ..\n",
       "2095  CEMENT  3\n",
       "2096  CEMENT  3\n",
       "2097  CEMENT  3\n",
       "2098  CEMENT  3\n",
       "2099  CEMENT  3\n",
       "\n",
       "[2100 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classes\n",
    "classes = pd.read_csv('./segmentation_data/segmentation_classes.txt', header=None, sep='\\t')\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform min-max normalizaion on the data matrix so that each feature is scaled to [0,1] range:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.431, 0.742, 0.   , ..., 0.124, 0.508, 0.832],\n",
       "       [0.336, 0.733, 0.   , ..., 0.127, 0.463, 0.837],\n",
       "       [0.885, 0.971, 0.   , ..., 0.113, 0.48 , 0.845],\n",
       "       ...,\n",
       "       [0.502, 0.625, 0.   , ..., 0.072, 0.541, 0.176],\n",
       "       [0.589, 0.613, 0.   , ..., 0.081, 0.503, 0.185],\n",
       "       [0.486, 0.629, 0.   , ..., 0.096, 0.48 , 0.17 ]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(dt)\n",
    "dt_norm = min_max_scaler.transform(dt)\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "dt_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> b. </h3>\n",
    "\n",
    "**Using Kmeans implementation in scikit-learn, perform clustering on the image data (use K=7 in your clustering)::**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 409.70644990612413\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 401.13845432174105\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 400.3585766012935\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 399.4181985295721\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 398.2503239866979\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 397.45575929538006\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 395.9737298367512\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 394.0709298514105\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 392.6164547488405\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 390.21212638096006\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 385.9366823275452\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 381.7829620964247\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 379.7520971419158\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 378.9937907716505\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 378.41353128949186\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 377.9959205978173\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 377.640847377035\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 377.20455496946033\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 376.52458920645415\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 375.4421976477309\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 20, inertia 373.9829619650248\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 21, inertia 371.56651487078904\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 22, inertia 369.87707874746104\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 23, inertia 369.38083187232075\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 24, inertia 369.16677504296706\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 25, inertia 369.0788270214457\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 26, inertia 369.0054786775162\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 27, inertia 368.9633456908135\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 28, inertia 368.923237692542\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 29, inertia 368.87613467650544\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 30, inertia 368.83952846594315\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 31, inertia 368.823124175151\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 32, inertia 368.8129283836879\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 33, inertia 368.8117454209989\n",
      "center shift 2.255092e-06 within tolerance 4.150157e-06\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 387.33467221892647\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 381.3468659721436\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 378.9906867106778\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 377.76131939390564\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 376.49462546452907\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 375.00027178194216\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 373.5664516470938\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 372.4041129226068\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 371.7154359537635\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 371.44841589864575\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 371.24158325517436\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 371.14116991605835\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 371.11178470663515\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 371.056062320384\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 371.025922277743\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 371.02309549619747\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 371.01905615124974\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 371.01905615124974\n",
      "center shift 0.000000e+00 within tolerance 4.150157e-06\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 415.9676182440181\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 386.38554808534656\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 382.14411759771747\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 379.36071479170295\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 374.24577086777055\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 370.3786067960947\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 370.00452342899644\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 369.9080182416039\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 369.86079247627293\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 369.8478489434334\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 369.8422794483229\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 369.84073795056116\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 369.83906546422315\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 369.83906546422315\n",
      "center shift 0.000000e+00 within tolerance 4.150157e-06\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 412.3278990798641\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 387.48563225376864\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 385.7246429444213\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 385.00784637672757\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 384.7025177445777\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 384.4488009072253\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 384.14707602397834\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 383.5696888672232\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 382.44293194352576\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 380.9730621714273\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 379.47372001525605\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 377.24743428692653\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 374.2535449303206\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 372.53184353213084\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 371.8372920448565\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 371.4398046746544\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 371.1968374814617\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 371.08487727586595\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 371.0423557576807\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 371.01326570950124\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 20, inertia 370.984917618474\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 21, inertia 370.9572996747208\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 22, inertia 370.9572996747208\n",
      "center shift 0.000000e+00 within tolerance 4.150157e-06\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 415.1543318106095\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 382.85231103139245\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 378.16639761314207\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 372.45691265964115\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 369.6292261197045\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 368.7402809344534\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 367.7429205197594\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 367.10392108424537\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 366.96807752716825\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 366.95356075341687\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 366.9525906656235\n",
      "center shift 2.859385e-06 within tolerance 4.150157e-06\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 407.49692244932373\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 371.7722830137193\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 367.70231101672965\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 366.3478039781303\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 365.2700137544541\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 363.62910817730426\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 361.781974985906\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 360.06194390056567\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 357.71337789859524\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 354.9061141348818\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 352.6996763053119\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 351.676467377512\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 351.35883189562844\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 351.1073440667824\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 350.80216056775686\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 350.3293179860852\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 350.0735910171652\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 350.03002648093286\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 350.025041469862\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 350.0173541333279\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 20, inertia 350.0129027194548\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 21, inertia 350.0129027194548\n",
      "center shift 0.000000e+00 within tolerance 4.150157e-06\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 404.1927275594095\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 389.32099653085845\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 385.6321021016496\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 380.37167156828787\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 375.49157517089986\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 373.63469844745936\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 372.83364049661736\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 371.7707849055017\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 370.84475661733927\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, inertia 370.133894363103\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 369.91379543577585\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 369.86528266029626\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 369.85888642081807\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 369.85888642081807\n",
      "center shift 0.000000e+00 within tolerance 4.150157e-06\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 429.57326707405514\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 407.42692007675896\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 404.33262564053905\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 403.43544947926495\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 403.25582250635216\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 403.16886620129316\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 403.03449566940833\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 402.76820008095734\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 402.02450000410965\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 400.19847317838656\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 398.8008818037468\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 397.6508211380253\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 396.86897155807014\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 396.6379143767734\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 396.5008086143261\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 396.43021792077485\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 396.4004028674715\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 396.3749917543257\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 396.3394167434335\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 396.3265816260598\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 20, inertia 396.3252736614277\n",
      "center shift 2.422838e-06 within tolerance 4.150157e-06\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 380.3041611200779\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 364.67416751885366\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 359.0845481954574\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 354.8713967584211\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 352.03223291305994\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 350.7761610970909\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 350.2683027350935\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 350.10378028247715\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 350.0447510203161\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 350.0115747924538\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 350.0115747924538\n",
      "center shift 0.000000e+00 within tolerance 4.150157e-06\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 422.08230932287927\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 382.5320383416565\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 377.60420159014564\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 375.4246239835643\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 373.8874186758985\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 372.93590965336455\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 372.2362341385075\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 371.61441274979666\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 370.9342327905339\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 370.3289251348838\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 369.9917345467186\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 369.7924723416949\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 369.72327304935754\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 369.690012333981\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 369.66945007785745\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 369.6541340447106\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 369.6496943696052\n",
      "center shift 2.304866e-06 within tolerance 4.150157e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=500,\n",
       "       n_clusters=7, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, max_iter=500, verbose=1) # initialization\n",
    "kmeans.fit(dt_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cluster\n",
       "0           3\n",
       "1           3\n",
       "2           3\n",
       "3           3\n",
       "4           3\n",
       "...       ...\n",
       "2095        1\n",
       "2096        2\n",
       "2097        5\n",
       "2098        5\n",
       "2099        2\n",
       "\n",
       "[2100 rows x 1 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = kmeans.predict(dt_norm)\n",
    "pd.DataFrame(clusters, columns=[\"Cluster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['REGION-CENTROID-COL',\n",
       " 'REGION-CENTROID-ROW',\n",
       " 'REGION-PIXEL-COUNT',\n",
       " 'SHORT-LINE-DENSITY-5',\n",
       " 'SHORT-LINE-DENSITY-2',\n",
       " 'VEDGE-MEAN',\n",
       " 'VEDGE-SD',\n",
       " 'HEDGE-MEAN',\n",
       " 'HEDGE-SD',\n",
       " 'INTENSITY-MEAN',\n",
       " 'RAWRED-MEAN',\n",
       " 'RAWBLUE-MEAN',\n",
       " 'RAWGREEN-MEAN',\n",
       " 'EXRED-MEAN',\n",
       " 'EXBLUE-MEAN',\n",
       " 'EXGREEN-MEAN',\n",
       " 'VALUE-MEAN',\n",
       " 'SATURATION-MEAN',\n",
       " 'HUE-MEAN']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = names[0].tolist()\n",
    "index_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the cluster centroids:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>REGION-CENTROID-COL</th>\n",
       "      <td>0.302506</td>\n",
       "      <td>0.253603</td>\n",
       "      <td>0.251678</td>\n",
       "      <td>0.513994</td>\n",
       "      <td>0.535099</td>\n",
       "      <td>0.769063</td>\n",
       "      <td>0.748274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REGION-CENTROID-ROW</th>\n",
       "      <td>0.530862</td>\n",
       "      <td>0.459865</td>\n",
       "      <td>0.392749</td>\n",
       "      <td>0.808937</td>\n",
       "      <td>0.150167</td>\n",
       "      <td>0.425930</td>\n",
       "      <td>0.532041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REGION-PIXEL-COUNT</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHORT-LINE-DENSITY-5</th>\n",
       "      <td>0.052260</td>\n",
       "      <td>0.026346</td>\n",
       "      <td>0.075622</td>\n",
       "      <td>0.077441</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.014024</td>\n",
       "      <td>0.039157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHORT-LINE-DENSITY-2</th>\n",
       "      <td>0.046610</td>\n",
       "      <td>0.013746</td>\n",
       "      <td>0.019403</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.022654</td>\n",
       "      <td>0.037651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VEDGE-MEAN</th>\n",
       "      <td>0.100817</td>\n",
       "      <td>0.037337</td>\n",
       "      <td>0.077657</td>\n",
       "      <td>0.054474</td>\n",
       "      <td>0.030228</td>\n",
       "      <td>0.039702</td>\n",
       "      <td>0.113530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VEDGE-SD</th>\n",
       "      <td>0.009420</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>0.018922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEDGE-MEAN</th>\n",
       "      <td>0.083972</td>\n",
       "      <td>0.027901</td>\n",
       "      <td>0.061240</td>\n",
       "      <td>0.046335</td>\n",
       "      <td>0.026766</td>\n",
       "      <td>0.023116</td>\n",
       "      <td>0.107311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEDGE-SD</th>\n",
       "      <td>0.011043</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.005037</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.017627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTENSITY-MEAN</th>\n",
       "      <td>0.400608</td>\n",
       "      <td>0.025942</td>\n",
       "      <td>0.147428</td>\n",
       "      <td>0.108790</td>\n",
       "      <td>0.823246</td>\n",
       "      <td>0.040385</td>\n",
       "      <td>0.298573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAWRED-MEAN</th>\n",
       "      <td>0.370347</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.137485</td>\n",
       "      <td>0.091403</td>\n",
       "      <td>0.779716</td>\n",
       "      <td>0.034426</td>\n",
       "      <td>0.277521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAWBLUE-MEAN</th>\n",
       "      <td>0.472461</td>\n",
       "      <td>0.042280</td>\n",
       "      <td>0.184391</td>\n",
       "      <td>0.092414</td>\n",
       "      <td>0.894170</td>\n",
       "      <td>0.057385</td>\n",
       "      <td>0.350081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAWGREEN-MEAN</th>\n",
       "      <td>0.353036</td>\n",
       "      <td>0.016464</td>\n",
       "      <td>0.117637</td>\n",
       "      <td>0.142676</td>\n",
       "      <td>0.788761</td>\n",
       "      <td>0.028059</td>\n",
       "      <td>0.263837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXRED-MEAN</th>\n",
       "      <td>0.497146</td>\n",
       "      <td>0.769272</td>\n",
       "      <td>0.718250</td>\n",
       "      <td>0.679161</td>\n",
       "      <td>0.270665</td>\n",
       "      <td>0.779917</td>\n",
       "      <td>0.593300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXBLUE-MEAN</th>\n",
       "      <td>0.570882</td>\n",
       "      <td>0.216204</td>\n",
       "      <td>0.343789</td>\n",
       "      <td>0.079002</td>\n",
       "      <td>0.666373</td>\n",
       "      <td>0.222795</td>\n",
       "      <td>0.449242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXGREEN-MEAN</th>\n",
       "      <td>0.213054</td>\n",
       "      <td>0.508343</td>\n",
       "      <td>0.354454</td>\n",
       "      <td>0.821287</td>\n",
       "      <td>0.289386</td>\n",
       "      <td>0.486886</td>\n",
       "      <td>0.311453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VALUE-MEAN</th>\n",
       "      <td>0.472461</td>\n",
       "      <td>0.043251</td>\n",
       "      <td>0.184648</td>\n",
       "      <td>0.134901</td>\n",
       "      <td>0.894170</td>\n",
       "      <td>0.058362</td>\n",
       "      <td>0.350163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SATURATION-MEAN</th>\n",
       "      <td>0.302263</td>\n",
       "      <td>0.802618</td>\n",
       "      <td>0.413414</td>\n",
       "      <td>0.414491</td>\n",
       "      <td>0.211804</td>\n",
       "      <td>0.539152</td>\n",
       "      <td>0.303047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUE-MEAN</th>\n",
       "      <td>0.163879</td>\n",
       "      <td>0.180506</td>\n",
       "      <td>0.202752</td>\n",
       "      <td>0.892333</td>\n",
       "      <td>0.125066</td>\n",
       "      <td>0.244988</td>\n",
       "      <td>0.164359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             1         2         3         4         5  \\\n",
       "REGION-CENTROID-COL   0.302506  0.253603  0.251678  0.513994  0.535099   \n",
       "REGION-CENTROID-ROW   0.530862  0.459865  0.392749  0.808937  0.150167   \n",
       "REGION-PIXEL-COUNT    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "SHORT-LINE-DENSITY-5  0.052260  0.026346  0.075622  0.077441  0.027778   \n",
       "SHORT-LINE-DENSITY-2  0.046610  0.013746  0.019403  0.005051  0.001667   \n",
       "VEDGE-MEAN            0.100817  0.037337  0.077657  0.054474  0.030228   \n",
       "VEDGE-SD              0.009420  0.002370  0.004149  0.001407  0.000543   \n",
       "HEDGE-MEAN            0.083972  0.027901  0.061240  0.046335  0.026766   \n",
       "HEDGE-SD              0.011043  0.002022  0.005037  0.001401  0.000587   \n",
       "INTENSITY-MEAN        0.400608  0.025942  0.147428  0.108790  0.823246   \n",
       "RAWRED-MEAN           0.370347  0.017775  0.137485  0.091403  0.779716   \n",
       "RAWBLUE-MEAN          0.472461  0.042280  0.184391  0.092414  0.894170   \n",
       "RAWGREEN-MEAN         0.353036  0.016464  0.117637  0.142676  0.788761   \n",
       "EXRED-MEAN            0.497146  0.769272  0.718250  0.679161  0.270665   \n",
       "EXBLUE-MEAN           0.570882  0.216204  0.343789  0.079002  0.666373   \n",
       "EXGREEN-MEAN          0.213054  0.508343  0.354454  0.821287  0.289386   \n",
       "VALUE-MEAN            0.472461  0.043251  0.184648  0.134901  0.894170   \n",
       "SATURATION-MEAN       0.302263  0.802618  0.413414  0.414491  0.211804   \n",
       "HUE-MEAN              0.163879  0.180506  0.202752  0.892333  0.125066   \n",
       "\n",
       "                             6         7  \n",
       "REGION-CENTROID-COL   0.769063  0.748274  \n",
       "REGION-CENTROID-ROW   0.425930  0.532041  \n",
       "REGION-PIXEL-COUNT    0.000000  0.000000  \n",
       "SHORT-LINE-DENSITY-5  0.014024  0.039157  \n",
       "SHORT-LINE-DENSITY-2  0.022654  0.037651  \n",
       "VEDGE-MEAN            0.039702  0.113530  \n",
       "VEDGE-SD              0.002983  0.018922  \n",
       "HEDGE-MEAN            0.023116  0.107311  \n",
       "HEDGE-SD              0.002094  0.017627  \n",
       "INTENSITY-MEAN        0.040385  0.298573  \n",
       "RAWRED-MEAN           0.034426  0.277521  \n",
       "RAWBLUE-MEAN          0.057385  0.350081  \n",
       "RAWGREEN-MEAN         0.028059  0.263837  \n",
       "EXRED-MEAN            0.779917  0.593300  \n",
       "EXBLUE-MEAN           0.222795  0.449242  \n",
       "EXGREEN-MEAN          0.486886  0.311453  \n",
       "VALUE-MEAN            0.058362  0.350163  \n",
       "SATURATION-MEAN       0.539152  0.303047  \n",
       "HUE-MEAN              0.244988  0.164359  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids = pd.DataFrame(kmeans.cluster_centers_.T, columns=['1','2','3','4','5','6','7'], index=index_name)\n",
    "centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To evaluate your clusters, first perform Silhouette analysis on the clusters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.572 0.561 0.465 0.496 0.572 0.56  0.542 0.412 0.52  0.468 0.487 0.491 0.584 0.563 0.379 0.531\n",
      " 0.548 0.423 0.416 0.404]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "silhouettes = metrics.silhouette_samples(dt_norm, clusters)\n",
    "print(silhouettes[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3320742908894385\n"
     ]
    }
   ],
   "source": [
    "print(silhouettes.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization of the Silhouettes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from sklearn.metrics import silhouette_samples\n",
    "\n",
    "def plot_silhouettes(dt_norm, clusters, metric='euclidean'):\n",
    "    cluster_labels = np.unique(clusters)\n",
    "    n_clusters = cluster_labels.shape[0]\n",
    "    silhouette_vals = metrics.silhouette_samples(dt_norm, clusters, metric='euclidean')\n",
    "    c_ax_lower, c_ax_upper = 0, 0\n",
    "    cticks = []\n",
    "    for i, k in enumerate(cluster_labels):\n",
    "        c_silhouette_vals = silhouette_vals[clusters == k]\n",
    "        c_silhouette_vals.sort()\n",
    "        c_ax_upper += len(c_silhouette_vals)\n",
    "        color = cm.jet(float(i) / n_clusters)\n",
    "        pl.barh(range(c_ax_lower, c_ax_upper), c_silhouette_vals, height=1.0, edgecolor='none', color=color)\n",
    "        \n",
    "        cticks.append((c_ax_lower + c_ax_upper) / 2)\n",
    "        c_ax_lower += len(c_silhouette_vals)\n",
    "        \n",
    "    silhouette_avg = np.mean(silhouette_vals)\n",
    "    pl.axvline(silhouette_avg, color='red', linestyle='--')\n",
    "    \n",
    "    pl.yticks(cticks, cluster_labels)\n",
    "    pl.ylabel('Cluster')\n",
    "    pl.xlabel('Silhouette coefficient')\n",
    "    \n",
    "    pl.tight_layout()\n",
    "    pl.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_silhouettes(dt_norm, clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing** `Completeness and Homogeneity` **values of the generated clusters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness:  0.6117374684331665\n",
      "Homogeneity :  0.6100499914689614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import completeness_score, homogeneity_score\n",
    "\n",
    "print(\"Completeness: \", completeness_score(classes[1], clusters))\n",
    "print(\"Homogeneity : \", homogeneity_score(classes[1], clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>c. </h3>\n",
    "\n",
    "**Perform PCA on the normalized image data matrix:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.689  0.533  0.246 ... -0.     0.    -0.   ]\n",
      " [-0.667  0.511  0.338 ...  0.    -0.    -0.   ]\n",
      " [-0.712  0.771 -0.156 ...  0.     0.    -0.   ]\n",
      " ...\n",
      " [-0.508 -0.129 -0.082 ... -0.     0.     0.   ]\n",
      " [-0.479 -0.086 -0.159 ... -0.     0.     0.   ]\n",
      " [-0.442 -0.106 -0.047 ... -0.     0.     0.   ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "pca = decomposition.PCA(svd_solver='randomized')\n",
    "XTrans = pca.fit_transform(dt_norm)\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "print(XTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.607 0.132 0.101 0.045 0.035 0.02  0.019 0.016 0.011 0.007 0.004 0.002 0.    0.    0.    0.\n",
      " 0.    0.    0.   ]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.08  0.    0.   -0.   -0.   -0.    0.   -0.    0.    0.    0.    0.01  0.01 -0.01  0.    0.\n",
      "   0.01 -0.01  0.  ]\n",
      " [ 0.    0.06  0.    0.    0.    0.   -0.    0.   -0.   -0.03 -0.03 -0.03 -0.03  0.02 -0.02  0.02\n",
      "  -0.03  0.    0.04]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.  ]\n",
      " [-0.    0.    0.    0.02 -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.    0.   -0.    0.\n",
      "  -0.   -0.    0.  ]\n",
      " [-0.    0.    0.   -0.    0.01  0.    0.    0.    0.   -0.   -0.   -0.   -0.   -0.    0.   -0.\n",
      "  -0.    0.   -0.  ]\n",
      " [-0.    0.    0.   -0.    0.    0.01  0.    0.    0.   -0.   -0.    0.   -0.   -0.    0.   -0.\n",
      "   0.   -0.   -0.  ]\n",
      " [ 0.   -0.    0.   -0.    0.    0.    0.    0.    0.   -0.   -0.    0.    0.   -0.    0.    0.\n",
      "   0.    0.   -0.  ]\n",
      " [-0.    0.    0.   -0.    0.    0.    0.    0.01  0.    0.    0.    0.    0.   -0.    0.   -0.\n",
      "   0.   -0.   -0.  ]\n",
      " [ 0.   -0.    0.   -0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   -0.    0.   -0.\n",
      "   0.   -0.   -0.  ]\n",
      " [ 0.   -0.03  0.   -0.   -0.   -0.   -0.    0.    0.    0.07  0.07  0.08  0.07 -0.04  0.04 -0.03\n",
      "   0.08 -0.04 -0.02]\n",
      " [ 0.   -0.03  0.   -0.   -0.   -0.   -0.    0.    0.    0.07  0.07  0.07  0.06 -0.04  0.04 -0.03\n",
      "   0.07 -0.04 -0.02]\n",
      " [ 0.01 -0.03  0.   -0.   -0.    0.    0.    0.    0.    0.08  0.07  0.08  0.07 -0.05  0.05 -0.03\n",
      "   0.08 -0.04 -0.03]\n",
      " [ 0.01 -0.03  0.   -0.   -0.   -0.    0.    0.    0.    0.07  0.06  0.07  0.06 -0.04  0.04 -0.02\n",
      "   0.07 -0.04 -0.02]\n",
      " [-0.01  0.02  0.    0.   -0.   -0.   -0.   -0.   -0.   -0.04 -0.04 -0.05 -0.04  0.04 -0.03  0.02\n",
      "  -0.05  0.02  0.01]\n",
      " [ 0.   -0.02  0.   -0.    0.    0.    0.    0.    0.    0.04  0.04  0.05  0.04 -0.03  0.04 -0.03\n",
      "   0.05 -0.02 -0.03]\n",
      " [ 0.    0.02  0.    0.   -0.   -0.    0.   -0.   -0.   -0.03 -0.03 -0.03 -0.02  0.02 -0.03  0.04\n",
      "  -0.03  0.01  0.04]\n",
      " [ 0.01 -0.03  0.   -0.   -0.    0.    0.    0.    0.    0.08  0.07  0.08  0.07 -0.05  0.05 -0.03\n",
      "   0.08 -0.04 -0.03]\n",
      " [-0.01  0.    0.   -0.    0.   -0.    0.   -0.   -0.   -0.04 -0.04 -0.04 -0.04  0.02 -0.02  0.01\n",
      "  -0.04  0.05 -0.  ]\n",
      " [ 0.    0.04  0.    0.   -0.   -0.   -0.   -0.   -0.   -0.02 -0.02 -0.03 -0.02  0.01 -0.03  0.04\n",
      "  -0.03 -0.    0.07]]\n"
     ]
    }
   ],
   "source": [
    "meanVals = np.mean(dt_norm, axis=0)\n",
    "meanRemoved = dt_norm- meanVals\n",
    "covMat = np.cov(meanRemoved, rowvar=0)\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=100)\n",
    "print(covMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigen Values: \n",
      " [0.48 0.1  0.08 0.04 0.03 0.02 0.01 0.01 0.01 0.01 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "eigen Vectors: \n",
      " [[ 0.03 -0.35  0.93  0.04  0.01 -0.03  0.01  0.03 -0.   -0.02 -0.01 -0.01  0.    0.    0.    0.\n",
      "  -0.    0.    0.  ]\n",
      " [-0.19 -0.38 -0.12 -0.66  0.47 -0.14 -0.24  0.22  0.06  0.07  0.06  0.04  0.01 -0.01 -0.    0.\n",
      "  -0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    1.  ]\n",
      " [-0.01 -0.03 -0.04 -0.03 -0.06 -0.6   0.72  0.32  0.06  0.08  0.01  0.01  0.   -0.   -0.    0.\n",
      "   0.   -0.    0.  ]\n",
      " [-0.    0.02  0.01 -0.1   0.09  0.44  0.28  0.32 -0.77  0.05  0.07  0.   -0.01  0.    0.   -0.\n",
      "  -0.   -0.    0.  ]\n",
      " [ 0.    0.02  0.01 -0.12  0.03  0.42  0.3   0.11  0.44 -0.34  0.55 -0.28  0.11 -0.01  0.    0.\n",
      "  -0.    0.    0.  ]\n",
      " [ 0.    0.01  0.01 -0.01  0.01  0.18  0.12  0.07  0.18 -0.14  0.05  0.77 -0.55  0.01 -0.   -0.\n",
      "  -0.   -0.    0.  ]\n",
      " [ 0.01  0.   -0.   -0.14  0.03  0.33  0.19  0.16  0.29 -0.02 -0.77 -0.29 -0.21 -0.01  0.   -0.\n",
      "   0.    0.    0.  ]\n",
      " [ 0.    0.    0.   -0.02  0.01  0.16  0.09  0.07  0.13 -0.05 -0.24  0.49  0.8   0.01  0.    0.\n",
      "   0.   -0.    0.  ]\n",
      " [ 0.38 -0.11 -0.06  0.09  0.05 -0.02 -0.08  0.16  0.01 -0.05  0.   -0.    0.   -0.21 -0.04  0.06\n",
      "   0.64 -0.63  0.  ]\n",
      " [ 0.36 -0.11 -0.07  0.09 -0.01 -0.04 -0.13  0.24  0.   -0.11 -0.   -0.01  0.   -0.21 -0.52  0.55\n",
      "  -0.5   0.02  0.  ]\n",
      " [ 0.41 -0.07 -0.04  0.03  0.08 -0.03 -0.04  0.07 -0.01 -0.06 -0.01  0.    0.   -0.22  0.81  0.1\n",
      "  -0.33  0.17  0.  ]\n",
      " [ 0.36 -0.16 -0.08  0.14  0.06  0.01 -0.08  0.18  0.04  0.02  0.02 -0.    0.   -0.21 -0.19 -0.73\n",
      "   0.18  0.45  0.  ]\n",
      " [-0.24  0.06  0.    0.01 -0.39 -0.13 -0.31  0.5  -0.05 -0.42 -0.04 -0.03  0.    0.08  0.11 -0.25\n",
      "  -0.17 -0.26  0.  ]\n",
      " [ 0.26  0.18  0.08 -0.27  0.18 -0.04  0.18 -0.4  -0.08 -0.08 -0.04  0.02 -0.   -0.08 -0.11 -0.3\n",
      "  -0.32 -0.45  0.  ]\n",
      " [-0.18 -0.34 -0.13  0.43  0.11  0.2   0.03  0.14  0.17  0.55  0.1  -0.   -0.    0.05  0.06 -0.07\n",
      "  -0.26 -0.32  0.  ]\n",
      " [ 0.41 -0.1  -0.06  0.04  0.1  -0.02 -0.03  0.06 -0.   -0.07 -0.01 -0.02 -0.    0.89  0.   -0.\n",
      "  -0.    0.    0.  ]\n",
      " [-0.2   0.31  0.08  0.42  0.74 -0.12 -0.03  0.13 -0.01 -0.3  -0.06 -0.03 -0.   -0.01 -0.    0.\n",
      "  -0.   -0.    0.  ]\n",
      " [-0.17 -0.64 -0.24  0.2  -0.01 -0.02  0.18 -0.35 -0.18 -0.5  -0.12 -0.02 -0.   -0.04 -0.    0.\n",
      "  -0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy.linalg as la\n",
    "eigVals, eigVects = la.eig(np.mat(covMat))\n",
    "print(\"eigen Values: \\n\",eigVals)\n",
    "print(\"eigen Vectors: \\n\", eigVects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48 0.1  0.08 0.04 0.03 0.02 0.01 0.01 0.01 0.01 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "[60.71 13.2  10.12  4.54  3.55  1.99  1.89  1.62  1.07  0.71  0.39  0.16  0.05  0.    0.    0.\n",
      "  0.    0.    0.  ]\n"
     ]
    }
   ],
   "source": [
    "eigValInd = np.argsort(eigVals) #sort, sort goes smallest to largest \n",
    "eigValInd = eigValInd[::-1] #reverse\n",
    "sortedEigVals = eigVals[eigValInd]\n",
    "print(sortedEigVals)\n",
    "total = sum(sortedEigVals)\n",
    "varPercentage = sortedEigVals/total*100\n",
    "print(varPercentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Determine the number,** `r` **of PCs needed to capture** `at least 95% of variance` **in the data,<br>\n",
    "provide a plot of PC variances:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(range(1, 11), varPercentage[:10], marker='^') \n",
    "plt.xlabel('Principal Component Number') \n",
    "plt.ylabel('Percentage of Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 60.71423396853327\n",
      "2: 73.91121320168926\n",
      "3: 84.0349861425619\n",
      "4: 88.57852534332585\n",
      "5: 92.12588648109568\n",
      "6: 94.11392197960622\n",
      "7: 96.00589227704955\n",
      "8: 97.62130108194515\n",
      "9: 98.6869019336203\n",
      "10: 99.39823945149531\n"
     ]
    }
   ],
   "source": [
    "total_percentage = 0\n",
    "for i in range(10):\n",
    "    total_percentage += varPercentage[i]\n",
    "    print(\"{}: {}\".format(i+1, total_percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use these r components as features to transform the data into a reduced dimension space:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.69 -0.53 -0.25 ...  0.08  0.05 -0.05]\n",
      " [-0.67 -0.51 -0.34 ...  0.04  0.06 -0.04]\n",
      " [-0.71 -0.77  0.16 ...  0.17  0.04 -0.06]\n",
      " ...\n",
      " [-0.51  0.13  0.08 ...  0.03 -0.03 -0.11]\n",
      " [-0.48  0.09  0.16 ... -0.   -0.   -0.09]\n",
      " [-0.44  0.11  0.05 ... -0.02 -0.21  0.15]]\n"
     ]
    }
   ],
   "source": [
    "topNfeat = 7\n",
    "topEigValInd = eigValInd[:topNfeat]\n",
    "reducedEigVects = eigVects[:, topEigValInd]\n",
    "reducedDT = np.dot(meanRemoved, reducedEigVects)\n",
    "print(reducedDT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>d. </h3>\n",
    "\n",
    "**Perform Kmeans again, but this time on the lower dimensional transformed data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 334.4045316839721\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 304.9952048863257\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 296.3450238064758\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 292.5118189091053\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 289.79499463801903\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 288.0230787767175\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 287.1785623123024\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 286.59970785220594\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 286.4839373379839\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 286.4542256121576\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 286.4442670547258\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 286.44306703718513\n",
      "center shift 3.606433e-06 within tolerance 1.081479e-05\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 375.4917666242744\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 335.40327372183725\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 321.167804371455\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 315.57378143278345\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 312.6299344232866\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 311.13945481947644\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 310.2940466886542\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 310.09248876750917\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 310.027841947405\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 309.9947809993656\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 309.9874487832466\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 309.98154684907615\n",
      "center shift 5.983739e-06 within tolerance 1.081479e-05\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 329.1647883396754\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 316.70011190309435\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 310.6232609232942\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 307.1836218359932\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 305.78091638242404\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 304.7050409333189\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 304.1347430938814\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 303.76063588946204\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 303.66034607907926\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 303.59659605856615\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 303.5691744270849\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 303.55449790486614\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 303.54748812574917\n",
      "center shift 5.168128e-06 within tolerance 1.081479e-05\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 305.5083991185911\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 295.5542592381163\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 291.1294202794298\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 289.33779543534996\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 287.802251290655\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 287.3104598647489\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 286.8662344668724\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 286.523649215343\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 286.4516582052565\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 286.4425683699064\n",
      "center shift 9.206378e-06 within tolerance 1.081479e-05\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 343.03063038951706\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 309.8158860450567\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 305.09443183980704\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 304.20207338800844\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 303.9778246675493\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 303.8899913296325\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 303.82573487898026\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 303.8126300379056\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 303.779091338256\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 303.69299521106916\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 303.62512446187066\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 303.5750846070204\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 303.5516284532021\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 303.5386125296533\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 303.5367147834995\n",
      "center shift 5.585791e-06 within tolerance 1.081479e-05\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 359.3851069991788\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 319.74112096254447\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 315.14065646923837\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 312.29368518434575\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 310.78714755551937\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 310.1990902627781\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 310.14053732014503\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 310.1094631509463\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 310.0439643059252\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 310.0028464862147\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 309.96191385550077\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 309.8963305658048\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 309.8902879254997\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 309.8902879254997\n",
      "center shift 0.000000e+00 within tolerance 1.081479e-05\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 319.91171183121196\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 309.62053459534985\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 306.4412677988678\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 305.1059622506849\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 304.4537875349648\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 303.9421943278529\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 303.6993554625669\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 303.6095515521023\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 303.57912465166396\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 303.55856978125314\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 303.54748812574917\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 303.5463271211725\n",
      "center shift 1.832857e-06 within tolerance 1.081479e-05\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 322.0066675825893\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 315.34189531115305\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 314.76476023007103\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 314.53796392236876\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 314.4620261602756\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 314.4525432494617\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 314.4156087530407\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 314.34139843142407\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 314.29721942579977\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 314.18080500894484\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 313.7899305689354\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 312.19872038146866\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 311.33298344034216\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 311.1915587397989\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 311.1386485579284\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 311.122929242632\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 311.1063693267492\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 311.0981967518529\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 311.04946845486035\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 311.0133423182558\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 20, inertia 310.9977476061902\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 21, inertia 310.9805664348698\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 22, inertia 310.9726454230589\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 23, inertia 310.9689756961424\n",
      "center shift 1.023519e-05 within tolerance 1.081479e-05\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 359.5702767121944\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 345.523808196462\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 332.21772411903476\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 322.3137896163212\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 319.6767533799019\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 319.38924680652144\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 319.30306987907966\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 319.2035681294768\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 319.19611003806176\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 319.1945921539299\n",
      "center shift 8.695096e-06 within tolerance 1.081479e-05\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 352.4327628121471\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 333.637013779306\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 328.76229816650584\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 325.9517503654911\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 325.0971868709097\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 324.9448140505359\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 324.88154973301306\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 324.85518895749055\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 324.8337474550965\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 324.8174504957346\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 324.8174504957346\n",
      "center shift 0.000000e+00 within tolerance 1.081479e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=500,\n",
       "       n_clusters=7, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=7, max_iter=500, verbose=1)\n",
    "kmeans.fit(reducedDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 6, 6, 2], dtype=int32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters= kmeans.predict(reducedDT)\n",
    "clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.603705</td>\n",
       "      <td>0.355503</td>\n",
       "      <td>-0.109197</td>\n",
       "      <td>0.129799</td>\n",
       "      <td>0.130911</td>\n",
       "      <td>-0.021603</td>\n",
       "      <td>-0.043882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.414527</td>\n",
       "      <td>-0.087223</td>\n",
       "      <td>-0.036765</td>\n",
       "      <td>0.173195</td>\n",
       "      <td>0.029922</td>\n",
       "      <td>-0.008973</td>\n",
       "      <td>-0.021573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.207423</td>\n",
       "      <td>0.246366</td>\n",
       "      <td>-0.152532</td>\n",
       "      <td>-0.056618</td>\n",
       "      <td>-0.130311</td>\n",
       "      <td>-0.005704</td>\n",
       "      <td>0.033045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.619268</td>\n",
       "      <td>-0.640250</td>\n",
       "      <td>-0.195829</td>\n",
       "      <td>0.086856</td>\n",
       "      <td>0.067760</td>\n",
       "      <td>0.008866</td>\n",
       "      <td>0.038372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.176404</td>\n",
       "      <td>-0.043698</td>\n",
       "      <td>0.265370</td>\n",
       "      <td>-0.184124</td>\n",
       "      <td>-0.027075</td>\n",
       "      <td>0.024341</td>\n",
       "      <td>0.003264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.435888</td>\n",
       "      <td>0.105299</td>\n",
       "      <td>-0.165257</td>\n",
       "      <td>-0.233499</td>\n",
       "      <td>0.045031</td>\n",
       "      <td>-0.007272</td>\n",
       "      <td>0.015049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.511579</td>\n",
       "      <td>0.064908</td>\n",
       "      <td>0.336145</td>\n",
       "      <td>0.065365</td>\n",
       "      <td>-0.078809</td>\n",
       "      <td>0.006240</td>\n",
       "      <td>-0.026261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6\n",
       "0 -0.603705  0.355503 -0.109197  0.129799  0.130911 -0.021603 -0.043882\n",
       "1  1.414527 -0.087223 -0.036765  0.173195  0.029922 -0.008973 -0.021573\n",
       "2 -0.207423  0.246366 -0.152532 -0.056618 -0.130311 -0.005704  0.033045\n",
       "3 -0.619268 -0.640250 -0.195829  0.086856  0.067760  0.008866  0.038372\n",
       "4  0.176404 -0.043698  0.265370 -0.184124 -0.027075  0.024341  0.003264\n",
       "5  0.435888  0.105299 -0.165257 -0.233499  0.045031 -0.007272  0.015049\n",
       "6 -0.511579  0.064908  0.336145  0.065365 -0.078809  0.006240 -0.026261"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids = pd.DataFrame(kmeans.cluster_centers_ )\n",
    "centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare Silhouette values as well as completeness and Homogeneity values of the new clusters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59 0.57 0.48 0.51 0.59 0.58 0.56 0.43 0.54 0.48 0.5  0.51 0.59 0.57 0.4  0.54 0.56 0.43 0.42\n",
      " 0.43]\n",
      "Silhouettes Mean:  0.35978002328686975\n"
     ]
    }
   ],
   "source": [
    "silhouettes = metrics.silhouette_samples(reducedDT, clusters)\n",
    "print(silhouettes[:20])\n",
    "print(\"Silhouettes Mean: \", silhouettes.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_silhouettes(reducedDT, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness:  0.6110721173142059\n",
      "Homogeneity :  0.6094646259197862\n"
     ]
    }
   ],
   "source": [
    "print(\"Completeness: \", completeness_score(classes[1], clusters))\n",
    "print(\"Homogeneity : \", homogeneity_score(classes[1], clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare these results with those obtained on the full data in part b:**<br>\n",
    "\n",
    "(full data)<br>\n",
    "Completeness:  0.6117374684331665<br>\n",
    "Homogeneity :  0.6100499914689614<br>\n",
    "<br>\n",
    "(new clusters)<br>\n",
    "Completeness:  0.6107955063694608<br>\n",
    "Homogeneity :  0.6091364049733291<br>\n",
    "<br>\n",
    "According to result in above, Completeness and Homgeneity from the full data and reduced Data shows similar and didn't see the big differences. Therefore, if we analyze big amounts of data, it's better to use the reduced data to improve the computaional speed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Item-Based Joke Recommendation\n",
    "\n",
    "<h3>a. </h3>\n",
    "\n",
    "**Load in the joke rating data and the joke test data into appropriate data structures:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.18</td>\n",
       "      <td>19.79</td>\n",
       "      <td>1.34</td>\n",
       "      <td>2.84</td>\n",
       "      <td>3.48</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.15</td>\n",
       "      <td>15.17</td>\n",
       "      <td>2.02</td>\n",
       "      <td>6.24</td>\n",
       "      <td>...</td>\n",
       "      <td>13.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.08</td>\n",
       "      <td>10.71</td>\n",
       "      <td>17.36</td>\n",
       "      <td>15.37</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.34</td>\n",
       "      <td>10.27</td>\n",
       "      <td>5.66</td>\n",
       "      <td>19.88</td>\n",
       "      <td>20.22</td>\n",
       "      <td>...</td>\n",
       "      <td>13.82</td>\n",
       "      <td>6.05</td>\n",
       "      <td>10.71</td>\n",
       "      <td>18.86</td>\n",
       "      <td>10.81</td>\n",
       "      <td>8.86</td>\n",
       "      <td>14.06</td>\n",
       "      <td>11.34</td>\n",
       "      <td>6.68</td>\n",
       "      <td>12.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.03</td>\n",
       "      <td>20.27</td>\n",
       "      <td>20.03</td>\n",
       "      <td>20.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>19.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.80</td>\n",
       "      <td>19.16</td>\n",
       "      <td>8.18</td>\n",
       "      <td>17.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.84</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.50</td>\n",
       "      <td>15.61</td>\n",
       "      <td>6.83</td>\n",
       "      <td>5.61</td>\n",
       "      <td>12.36</td>\n",
       "      <td>12.60</td>\n",
       "      <td>18.04</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.56</td>\n",
       "      <td>16.73</td>\n",
       "      <td>...</td>\n",
       "      <td>16.19</td>\n",
       "      <td>16.58</td>\n",
       "      <td>15.27</td>\n",
       "      <td>16.19</td>\n",
       "      <td>16.73</td>\n",
       "      <td>12.55</td>\n",
       "      <td>14.11</td>\n",
       "      <td>17.55</td>\n",
       "      <td>12.80</td>\n",
       "      <td>12.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>12.94</td>\n",
       "      <td>5.47</td>\n",
       "      <td>16.19</td>\n",
       "      <td>5.51</td>\n",
       "      <td>6.92</td>\n",
       "      <td>8.48</td>\n",
       "      <td>14.20</td>\n",
       "      <td>14.83</td>\n",
       "      <td>4.98</td>\n",
       "      <td>13.96</td>\n",
       "      <td>...</td>\n",
       "      <td>6.58</td>\n",
       "      <td>9.93</td>\n",
       "      <td>15.37</td>\n",
       "      <td>7.89</td>\n",
       "      <td>13.72</td>\n",
       "      <td>6.87</td>\n",
       "      <td>13.23</td>\n",
       "      <td>5.47</td>\n",
       "      <td>14.54</td>\n",
       "      <td>13.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>15.27</td>\n",
       "      <td>11.39</td>\n",
       "      <td>16.39</td>\n",
       "      <td>5.37</td>\n",
       "      <td>7.41</td>\n",
       "      <td>16.58</td>\n",
       "      <td>12.17</td>\n",
       "      <td>2.84</td>\n",
       "      <td>5.13</td>\n",
       "      <td>4.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>16.58</td>\n",
       "      <td>16.63</td>\n",
       "      <td>15.85</td>\n",
       "      <td>7.89</td>\n",
       "      <td>14.40</td>\n",
       "      <td>9.74</td>\n",
       "      <td>14.54</td>\n",
       "      <td>13.14</td>\n",
       "      <td>6.34</td>\n",
       "      <td>11.78</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>3.67</td>\n",
       "      <td>4.45</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>9.40</td>\n",
       "      <td>7.65</td>\n",
       "      <td>3.86</td>\n",
       "      <td>4.40</td>\n",
       "      <td>3.67</td>\n",
       "      <td>4.93</td>\n",
       "      <td>...</td>\n",
       "      <td>3.82</td>\n",
       "      <td>6.87</td>\n",
       "      <td>6.87</td>\n",
       "      <td>3.77</td>\n",
       "      <td>3.77</td>\n",
       "      <td>3.77</td>\n",
       "      <td>3.77</td>\n",
       "      <td>3.77</td>\n",
       "      <td>3.77</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>9.88</td>\n",
       "      <td>11.73</td>\n",
       "      <td>9.16</td>\n",
       "      <td>9.50</td>\n",
       "      <td>13.52</td>\n",
       "      <td>12.07</td>\n",
       "      <td>14.50</td>\n",
       "      <td>11.97</td>\n",
       "      <td>13.28</td>\n",
       "      <td>11.68</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3      4      5      6      7      8      9   \\\n",
       "0     3.18  19.79   1.34   2.84   3.48   2.50   1.15  15.17   2.02   6.24   \n",
       "1    15.08  10.71  17.36  15.37   8.62   1.34  10.27   5.66  19.88  20.22   \n",
       "2     0.00   0.00   0.00   0.00  20.03  20.27  20.03  20.27   0.00   0.00   \n",
       "3     0.00  19.35   0.00   0.00  12.80  19.16   8.18  17.21   0.00  12.84   \n",
       "4    19.50  15.61   6.83   5.61  12.36  12.60  18.04  15.61  10.56  16.73   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "995  12.94   5.47  16.19   5.51   6.92   8.48  14.20  14.83   4.98  13.96   \n",
       "996  15.27  11.39  16.39   5.37   7.41  16.58  12.17   2.84   5.13   4.30   \n",
       "997  16.58  16.63  15.85   7.89  14.40   9.74  14.54  13.14   6.34  11.78   \n",
       "998   3.67   4.45   3.67   3.67   9.40   7.65   3.86   4.40   3.67   4.93   \n",
       "999   9.88  11.73   9.16   9.50  13.52  12.07  14.50  11.97  13.28  11.68   \n",
       "\n",
       "     ...     90     91     92     93     94     95     96     97     98     99  \n",
       "0    ...  13.82   0.00   0.00   0.00   0.00   0.00   5.37   0.00   0.00   0.00  \n",
       "1    ...  13.82   6.05  10.71  18.86  10.81   8.86  14.06  11.34   6.68  12.07  \n",
       "2    ...   0.00   0.00   0.00  20.08   0.00   0.00   0.00   0.00   0.00   0.00  \n",
       "3    ...   0.00   0.00   0.00  11.53   0.00   0.00   0.00   0.00   0.00   0.00  \n",
       "4    ...  16.19  16.58  15.27  16.19  16.73  12.55  14.11  17.55  12.80  12.60  \n",
       "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "995  ...   6.58   9.93  15.37   7.89  13.72   6.87  13.23   5.47  14.54  13.38  \n",
       "996  ...   0.00   0.00   0.00   0.00   6.58   0.00   0.00   0.00   0.00   0.00  \n",
       "997  ...   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  \n",
       "998  ...   3.82   6.87   6.87   3.77   3.77   3.77   3.77   3.77   3.77   3.28  \n",
       "999  ...   0.00   0.00   0.00   0.00  12.12   0.00   0.00   0.00   0.00   0.00  \n",
       "\n",
       "[1000 rows x 100 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ratings = pd.read_csv(\"./jokes/modified_jester_data.csv\", header=None)\n",
    "user_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man visits the doctor. The doctor says \"I ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This couple had an excellent relationship goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q. What's 200 feet long and has 4 teeth? A. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q. What's the difference between a man and a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q. What's O. J. Simpson's Internet address? A....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Two attorneys went into a diner and ordered tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A teacher is explaining to her class how diffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Age and Womanhood1. Between the ages of 13 and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>A bus station is where a bus stops.A train sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Q: What's the difference between greeting a Qu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "0                                                    \n",
       "0   A man visits the doctor. The doctor says \"I ha...\n",
       "1   This couple had an excellent relationship goin...\n",
       "2   Q. What's 200 feet long and has 4 teeth? A. Th...\n",
       "3   Q. What's the difference between a man and a t...\n",
       "4   Q. What's O. J. Simpson's Internet address? A....\n",
       "..                                                ...\n",
       "95  Two attorneys went into a diner and ordered tw...\n",
       "96  A teacher is explaining to her class how diffe...\n",
       "97  Age and Womanhood1. Between the ages of 13 and...\n",
       "98  A bus station is where a bus stops.A train sta...\n",
       "99  Q: What's the difference between greeting a Qu...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jokes = pd.read_csv(\"./jokes/jokes.csv\", header=None, index_col=0)\n",
    "jokes.columns = range(1)\n",
    "jokes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the \"recommend\" function to provide top 5 joke recommendation for at least 2 users.**<br>\n",
    "**Use both standard item-based collaborative filtering (based on the rating prediction function \"standEst\") and <br>\n",
    "the SVD-based version of the item-based CF (using \"svdEst\" as the prediction engine):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidSim(inA, inB):\n",
    "    return 1.0/(1.0 + la.norm(inA - inB))\n",
    "\n",
    "def pearsonSim(inA, inB):\n",
    "    if len(inA) < 3 :\n",
    "        return 1.0\n",
    "    return 0.5+0.5*corrcoef(inA, inB, rowvar=0)[0][1]\n",
    "\n",
    "def cosineSim(inA, inB):\n",
    "    num = float(inA.T*inB)\n",
    "    denom = la.norm(inA)*la.norm(inB)\n",
    "    return 0.5+0.5*(num/denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(x, D):\n",
    "    a_norm = np.linalg.norm(x)\n",
    "    b_norm = np.linalg.norm(D)\n",
    "    sims = np.dot(x, D)/(a_norm * b_norm) # calculate similarity\n",
    "    dists = 1 - sims\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standEst(dataMat, user, simMeas, item):\n",
    "    n = shape(dataMat)[1]\n",
    "    simTotal = 0.0\n",
    "    ratSimTotal = 0.0\n",
    "    for j in range(n):\n",
    "        userRating = dataMat[user, j]\n",
    "        if userRating == 0:\n",
    "            continue\n",
    "        overLap = nonzero(logical_and(dataMat[:,item]>0, dataMat[:,j]>0))[0]\n",
    "        if len(overLap) == 0:\n",
    "            similarity = 0\n",
    "        else:\n",
    "            similarity = simMeas(dataMat[overLap, item], dataMat[overLap, j])\n",
    "        simTotal += similarity\n",
    "        ratSimTotal += similarity * userRating\n",
    "    if simTotal == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return ratSimTotal/simTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svdEst(dataMat, user, simMeas, item):\n",
    "    n = shape(dataMat)[1]\n",
    "    simTotal = 0.0\n",
    "    ratSimTotal = 0.0\n",
    "    data = mat(dataMat)\n",
    "    U, Sigma, VT = la.svd(data)\n",
    "    Sig4 = mat(eye(4)*Sigma[:4])\n",
    "    xformedItems = data.T * U[:,:4] * Sig4.I\n",
    "    for j in range(n):\n",
    "        userRating = data[user,j]\n",
    "        if userRating == 0 or j == item:\n",
    "            continue\n",
    "        similarity = simMeas(xformedItems[item,:].T, xformedItems[j,:].T)\n",
    "        simTotal += similarity\n",
    "        ratSimTotal += similarity * userRating\n",
    "    if simTotal == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return ratSimTotal/simTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(dataMat, user, N=3, simMeas=cosineSim, estMethod=standEst):\n",
    "    unratedItems = nonzero(dataMat[user,:].A==0)[1]\n",
    "    if len(unratedItems)== 0:\n",
    "        return 'you rated everything'\n",
    "    itemScores = []\n",
    "    for item in unratedItems:\n",
    "        estimatedScore = estMethod(dataMat, user, simMeas, item)\n",
    "        itemScores.append((item, estimatedScore))\n",
    "    return sorted(itemScores, key=lambda jj: jj[1], reverse=True)[:N]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate recommendations for the two usersand show the text of the recommended jokes as well as the predicted rating for each:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(79, 12.69433859440884), (97, 12.69382673446855), (82, 12.693416493041948), (99, 12.693121655424392), (78, 12.692513849286719)]\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "\n",
    "D = np.mat(user_ratings)\n",
    "user1 = 31\n",
    "\n",
    "user1_recommend_stdEst = recommend(D, user1, N=5, simMeas=cosineSim, estMethod=standEst)\n",
    "print(user1_recommend_stdEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended top 5 jokes for User 31 (standEst):\n",
      "\n",
      "* Joke 79 with predicted rating: 12.69433859440884\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Hillary Bill Clinton and the Pope are sitting together on an airplane. Bill says \"I could throw one thousand dollar bill out of this plane and make one person very happy.\"Hillary says \"I could throw 10 hundred dollar bills out of the plane and make 10 people very happy.\"The Pope chips in and says \"I could throw Bill out of the airplane and make the whole country happy.\" \n",
      "\n",
      "* Joke 97 with predicted rating: 12.69382673446855\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Age and Womanhood1. Between the ages of 13 and 18 ... She is like Africa virgin and unexplored. 2. Between the ages of 19 and 35 ... She is like Asia hot and exotic. 3. Between the ages of 36 and 45 ... She is like America fully explored breathtakingly beautiful and free with her resources.4. Between the ages of 46 and 56 ...She is like Europe exhausted but still has points of interest. 5. After 56 she is like Australia ...Everybody knows it's down there but who gives a damn? \n",
      "\n",
      "* Joke 82 with predicted rating: 12.693416493041948\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "What a woman says:\"This place is a mess!  C'monYou and I need to clean upYour stuff is lying on the floor and you'll have no clothes to wear if we don't do laundry right now!\"What a man hears:blah blah blah blah C'mon blah blah blah blah you and I blah blah blah blah on the floor blah blah blah blah no clothes blah blah blah blah RIGHT NOW! \n",
      "\n",
      "* Joke 99 with predicted rating: 12.693121655424392\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Q: What's the difference between greeting a Queen and greeting thePresident of the United  States?A: You only have to get on one knee to greet the queen. \n",
      "\n",
      "* Joke 78 with predicted rating: 12.692513849286719\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Q: Ever wonder why the IRS calls it Form 1040?A: Because for every $50 that you earn you get 10 and they get 40. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Recommended top 5 jokes for User\", user1, \"(standEst):\\n\") \n",
    "for i, p in user1_recommend_stdEst:\n",
    "    print(\"* Joke\", i, \"with predicted rating:\", p)\n",
    "    print(\"-\"*110)\n",
    "    print(jokes[0][i],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(99, 12.85435913389405), (78, 12.852551576070857), (72, 12.844608423598794), (79, 12.844421427249832), (76, 12.83634895653827)]\n"
     ]
    }
   ],
   "source": [
    "user1_recommend_svdEst = recommend(D, user1, N=5, simMeas=cosineSim, estMethod=svdEst)\n",
    "print(user1_recommend_svdEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended top 5 jokes for User 31 (svdEst):\n",
      "\n",
      "* Joke 99 with predicted rating: 12.85435913389405\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Q: What's the difference between greeting a Queen and greeting thePresident of the United  States?A: You only have to get on one knee to greet the queen. \n",
      "\n",
      "* Joke 78 with predicted rating: 12.852551576070857\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Q: Ever wonder why the IRS calls it Form 1040?A: Because for every $50 that you earn you get 10 and they get 40. \n",
      "\n",
      "* Joke 72 with predicted rating: 12.844608423598794\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Q: What is the difference between George  Washington Richard Nixon and Bill Clinton? A: Washington couldn't tell a lie Nixon couldn't   tell the truth andClinton doesn't know the difference. \n",
      "\n",
      "* Joke 79 with predicted rating: 12.844421427249832\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Hillary Bill Clinton and the Pope are sitting together on an airplane. Bill says \"I could throw one thousand dollar bill out of this plane and make one person very happy.\"Hillary says \"I could throw 10 hundred dollar bills out of the plane and make 10 people very happy.\"The Pope chips in and says \"I could throw Bill out of the airplane and make the whole country happy.\" \n",
      "\n",
      "* Joke 76 with predicted rating: 12.83634895653827\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "If pro- is the opposite of con- then congress must be the opposite of progress. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Recommended top 5 jokes for User\", user1, \"(svdEst):\\n\") \n",
    "for i, p in user1_recommend_svdEst:\n",
    "    print(\"* Joke\", i, \"with predicted rating:\", p)\n",
    "    print(\"-\"*110)\n",
    "    print(jokes[0][i],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(97, 16.288515111446177), (71, 16.286900406031137), (79, 16.285489384198208), (99, 16.285361676559504), (82, 16.284922798716934)]\n"
     ]
    }
   ],
   "source": [
    "user2 = 12\n",
    "\n",
    "user2_recommend_stdEst = recommend(D, user2, N=5, simMeas=cosineSim, estMethod=standEst)\n",
    "print(user2_recommend_stdEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended top 5 jokes for User 12 (standEst):\n",
      "\n",
      "* Joke 97 with predicted rating: 16.288515111446177\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Age and Womanhood1. Between the ages of 13 and 18 ... She is like Africa virgin and unexplored. 2. Between the ages of 19 and 35 ... She is like Asia hot and exotic. 3. Between the ages of 36 and 45 ... She is like America fully explored breathtakingly beautiful and free with her resources.4. Between the ages of 46 and 56 ...She is like Europe exhausted but still has points of interest. 5. After 56 she is like Australia ...Everybody knows it's down there but who gives a damn? \n",
      "\n",
      "* Joke 71 with predicted rating: 16.286900406031137\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "On the first day of college the Dean addressed the students pointing out some of the rules:\"The female dormitory will be out-of-bounds for all male students and the male dormitory to the female students. Anybody caught breaking this rule will be fined $20 the first time.\" He continued \"Anybody caught breaking this rule the second time will be fined $60. Being caught a third time will cost you a fine of $180. Are there any questions ?\"At this point a male student in the crowd inquired:\"How much for a season pass ?\" \n",
      "\n",
      "* Joke 79 with predicted rating: 16.285489384198208\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Hillary Bill Clinton and the Pope are sitting together on an airplane. Bill says \"I could throw one thousand dollar bill out of this plane and make one person very happy.\"Hillary says \"I could throw 10 hundred dollar bills out of the plane and make 10 people very happy.\"The Pope chips in and says \"I could throw Bill out of the airplane and make the whole country happy.\" \n",
      "\n",
      "* Joke 99 with predicted rating: 16.285361676559504\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Q: What's the difference between greeting a Queen and greeting thePresident of the United  States?A: You only have to get on one knee to greet the queen. \n",
      "\n",
      "* Joke 82 with predicted rating: 16.284922798716934\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "What a woman says:\"This place is a mess!  C'monYou and I need to clean upYour stuff is lying on the floor and you'll have no clothes to wear if we don't do laundry right now!\"What a man hears:blah blah blah blah C'mon blah blah blah blah you and I blah blah blah blah on the floor blah blah blah blah no clothes blah blah blah blah RIGHT NOW! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Recommended top 5 jokes for User\", user2, \"(standEst):\\n\") \n",
    "for i, p in user2_recommend_stdEst:\n",
    "    print(\"* Joke\", i, \"with predicted rating:\", p)\n",
    "    print(\"-\"*110)\n",
    "    print(jokes[0][i],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(11, 16.631923410439267), (25, 16.615212442669787), (51, 16.573431872324196), (5, 16.548918764203684), (50, 16.486687735649674)]\n"
     ]
    }
   ],
   "source": [
    "user2_recommend_svdEst = recommend(D, user2, N=5, simMeas=cosineSim, estMethod=svdEst)\n",
    "print(user2_recommend_svdEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended top 5 jokes for User 12 (svdEst):\n",
      "\n",
      "* Joke 11 with predicted rating: 16.631923410439267\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "A guy stood over his tee shot for what seemed an eternity looking up looking down measuring the distance figuring the wind direction and speed. Driving his partner nuts.Finally his exasperated partner says \"What the hell is taking so long? Hit the goddamn ball!\"The guy answers \"My wife is up there watching me from the clubhouse. I want to make this a perfect shot.\"\"Well hell man you don't stand a snowball's chance in hell of hitting her from here!\"  \n",
      "\n",
      "* Joke 25 with predicted rating: 16.615212442669787\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "A guy walks into a bar and sits down next to an extremely gorgeous woman.  The first thing he notices about her though are her pants.  They were skin-tight high-waisted and had no obvious mechanism (zipper buttons or velcro) for opening them.After several minutes of puzzling over how she got the pants up over her hips he finally worked up the nerve to ask her.  \"Excuse me miss but how do you get into your pants?\"\"Well\" she replied \"you can start by buying me a drink.\" \n",
      "\n",
      "* Joke 51 with predicted rating: 16.573431872324196\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Q: What do Monica Lewinsky and Bob Dole have in common?A: They were both upset when Bill finished first. \n",
      "\n",
      "* Joke 5 with predicted rating: 16.548918764203684\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Bill & Hillary are on a trip back to Arkansas. They're almost out of gas so Bill pulls into a service station on the outskirts of town. The attendant runs out of the station to serve them when Hillary realizes it's an old boyfriend from high school. She and the attendant chat as he gases up their car and cleans the windows. Then they all say good-bye. As Bill pulls the car onto the road he turns to Hillary and says 'Now aren't you glad you married me and not him ? You could've been the wife of a grease monkey !' To which Hillary replied 'No Bill. If I would have married him you'd be pumping gas and he would be the President !'  \n",
      "\n",
      "* Joke 50 with predicted rating: 16.486687735649674\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Did you hear that Clinton has announced there is a new national bird?  The spread eagle. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Recommended top 5 jokes for User\", user2, \"(svdEst):\\n\") \n",
    "for i, p in user2_recommend_svdEst:\n",
    "    print(\"* Joke\", i, \"with predicted rating:\", p)\n",
    "    print(\"-\"*110)\n",
    "    print(jokes[0][i],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>b. </h3>\n",
    "\n",
    "**Complete the definition for the function \"test\". This function interates over all users and for each performs evaluation (by calling the provided \"cross_validate_user\" function), and returns the error information to compute Mean Absolute Error(MAE):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_user(dataMat, user, test_ratio, estMethod=standEst, simMeas=pearsonSim):\n",
    "    dataMat = np.array(dataMat)\n",
    "    number_of_items = np.shape(dataMat)[1]\n",
    "    rated_items_by_user = np.array([i for i in range(number_of_items) if dataMat[user,i]>0])\n",
    "    test_size = int(test_ratio * len(rated_items_by_user))\n",
    "    test_indices = np.random.randint(0, len(rated_items_by_user), test_size)\n",
    "    withheld_items = rated_items_by_user[test_indices]\n",
    "    original_user_profile = np.copy(dataMat[user])\n",
    "    dataMat[user, withheld_items] = 0 # So that the withheld test items is not used in the rating estimation below\n",
    "    error_u = 0.0\n",
    "    count_u = len(withheld_items)\n",
    "\n",
    "    # Compute absolute error for user u over all test items\n",
    "    for item in withheld_items:\n",
    "        # Estimate rating on the withheld item\n",
    "        estimatedScore = estMethod(dataMat, user, simMeas, item)\n",
    "        error_u = error_u + abs(estimatedScore - original_user_profile[item])\n",
    "\n",
    "    # Now restore ratings of the withheld items to the user profile\n",
    "    for item in withheld_items:\n",
    "        dataMat[user, item] = original_user_profile[item]\n",
    "\n",
    "    # Return sum of absolute errors and the count of test cases for this user\n",
    "    # Note that these will have to be accumulated for each user to compute MAE\n",
    "    return error_u, count_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataMat, test_ratio, estMethod, simMeas=pearsonSim):\n",
    "    # Write this function to iterate over all users and for each perform evaluation by calling\n",
    "    # the above cross_validate_user function on each user. MAE will be the ratio of total error \n",
    "    # across all test cases to the total number of test cases, across all users\n",
    "    \n",
    "    count = 0\n",
    "    errors = 0\n",
    "    for i in dataMat:\n",
    "        error_u, count_u = cross_validate_user(dataMat, i, test_ratio, estMethod, simMeas=pearsonSim)\n",
    "        count += count_u\n",
    "        errors += error_u\n",
    "        \n",
    "    MAE = errors/count\n",
    "    \n",
    "    return MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use this function to perform evaluation (with 20% test-ratio for each user) comparing MAE results using the rating predidction function \"standEst\" with results using the \"svdEst\" prediction function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE using standEst: 3.6936639782121383\n",
      "MAE using svdEst: 3.62654468538881\n"
     ]
    }
   ],
   "source": [
    "stdEst_mae = test(user_ratings, 0.2, standEst)\n",
    "print(\"MAE using standEst:\", stdEst_mae)\n",
    "svdEst_mae = test(user_ratings, 0.2, svdEst)\n",
    "print(\"MAE using svdEst:\", svdEst_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>c. </h3>\n",
    "\n",
    "**Write a new function \"print_most_similar_jokes\" which takes the joke ratings data, a query joke id, a parameter k for the number similar jokes, and a similarity metric function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_most_similar_jokes(dataMat, jokes, queryJoke, k, metric=pearsonSim):\n",
    "    # Write this function to find the k most similar jokes (based on user ratings) to a queryJoke\n",
    "    # The queryJoke is a joke id as given in the 'jokes.csv' file (an corresponding to the a column in dataMat)\n",
    "    # You must compare ratings for the queryJoke (the column in dataMat corresponding to the joke), to all\n",
    "    # other joke rating vectors and return the top k. Note that this is the same as performing KNN on the \n",
    "    # columns of dataMat. The function must retrieve the text of the joke from 'jokes.csv' file and print both\n",
    "    # the queryJoke text as well as the text of the returned top-k jokes.\n",
    "    \n",
    "    jokeRow = dataMat.T # joke rows\n",
    "    similarity = []\n",
    "    \n",
    "    for j in range(len(jokeRow)):\n",
    "        if(j == queryJoke):\n",
    "            continue\n",
    "        s = metric(jokeRow[queryJoke], jokeRow[j])\n",
    "        similarity.append((s,j))\n",
    "    similarity.sort(reverse=True) \n",
    "    \n",
    "    return similarity   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prints the text of the query joke as well as the texts of the top k most similar jokes based on user ratings:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Top 5 Most Similar Jokes >\n",
      "\n",
      "Queriy Joke: \n",
      " A man visits the doctor. The doctor says \"I have bad news for you.You have cancer and Alzheimer's disease\". The man replies \"Well thank God I don't have cancer!\" \n",
      "\n",
      "Top 1 similar joke, Similarity: 0.815454198811544\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Q. What's the difference between a man and a toilet? A. A toilet doesn't follow you around after you use it. \n",
      "\n",
      "Top 2 similar joke, Similarity: 0.8147499071164566\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Q: What do Monica Lewinsky and Bob Dole have in common?A: They were both upset when Bill finished first. \n",
      "\n",
      "Top 3 similar joke, Similarity: 0.8028810108537636\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Q: How do you keep a computer programmer in the shower all day long?A: Give them a shampoo with a label that says\"rinse lather repeat\". \n",
      "\n",
      "Top 4 similar joke, Similarity: 0.80124379126305\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "A woman has twins and gives them up for adoption.  One of them goes to a family in Egypt and is named \"Amal.\"  The other goes to a  family in Spain; they name him \"Juan.\"  Years later Juan sends a picture of himself to his mom.  Upon receiving the picture she tells her husband that she wishes she also had a picture of Amal.  Her husband responds \"But they are twins-if you've seen Juan you've seen   Amal. \n",
      "\n",
      "Top 5 similar joke, Similarity: 0.7988636921039397\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "What's the difference between a MacIntosh and anEtch-A-Sketch? You don't have to shake the Mac to clear the screen.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "queryJoke = 0\n",
    "k = 5\n",
    "sims = print_most_similar_jokes(user_ratings, jokes, queryJoke, k, metric=pearsonSim)\n",
    "\n",
    "print(\"< Top %d Most Similar Jokes >\\n\" %k)\n",
    "print(\"Queriy Joke:\",\"\\n\", jokes[0][queryJoke],\"\\n\")\n",
    "\n",
    "for i in range(k):\n",
    "    joke, idx = sims[i]\n",
    "    print(\"Top %d similar joke, Similarity:\" %(i+1), joke)\n",
    "    print(\"-\"*110)\n",
    "    print(jokes.iloc[idx][0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>d.</h3>\n",
    "\n",
    "**Develop your own item-based collaborative filtering recommender that uses a model-based approach (separating the training and the prediction tasks):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.18</td>\n",
       "      <td>15.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.50</td>\n",
       "      <td>4.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.84</td>\n",
       "      <td>7.21</td>\n",
       "      <td>14.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.38</td>\n",
       "      <td>13.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.54</td>\n",
       "      <td>12.94</td>\n",
       "      <td>15.27</td>\n",
       "      <td>16.58</td>\n",
       "      <td>3.67</td>\n",
       "      <td>9.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.79</td>\n",
       "      <td>10.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.35</td>\n",
       "      <td>15.61</td>\n",
       "      <td>7.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.16</td>\n",
       "      <td>7.46</td>\n",
       "      <td>16.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.27</td>\n",
       "      <td>7.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.83</td>\n",
       "      <td>5.47</td>\n",
       "      <td>11.39</td>\n",
       "      <td>16.63</td>\n",
       "      <td>4.45</td>\n",
       "      <td>11.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.34</td>\n",
       "      <td>17.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.83</td>\n",
       "      <td>11.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.17</td>\n",
       "      <td>1.58</td>\n",
       "      <td>16.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.57</td>\n",
       "      <td>9.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.38</td>\n",
       "      <td>16.19</td>\n",
       "      <td>16.39</td>\n",
       "      <td>15.85</td>\n",
       "      <td>3.67</td>\n",
       "      <td>9.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.84</td>\n",
       "      <td>15.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.61</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.79</td>\n",
       "      <td>4.11</td>\n",
       "      <td>14.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.98</td>\n",
       "      <td>8.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.57</td>\n",
       "      <td>5.51</td>\n",
       "      <td>5.37</td>\n",
       "      <td>7.89</td>\n",
       "      <td>3.67</td>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.48</td>\n",
       "      <td>8.62</td>\n",
       "      <td>20.03</td>\n",
       "      <td>12.80</td>\n",
       "      <td>12.36</td>\n",
       "      <td>3.91</td>\n",
       "      <td>19.59</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.26</td>\n",
       "      <td>17.41</td>\n",
       "      <td>...</td>\n",
       "      <td>12.07</td>\n",
       "      <td>2.02</td>\n",
       "      <td>7.65</td>\n",
       "      <td>13.96</td>\n",
       "      <td>17.84</td>\n",
       "      <td>6.92</td>\n",
       "      <td>7.41</td>\n",
       "      <td>14.40</td>\n",
       "      <td>9.40</td>\n",
       "      <td>13.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.00</td>\n",
       "      <td>8.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.55</td>\n",
       "      <td>7.65</td>\n",
       "      <td>13.33</td>\n",
       "      <td>7.65</td>\n",
       "      <td>10.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.06</td>\n",
       "      <td>6.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.37</td>\n",
       "      <td>14.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.11</td>\n",
       "      <td>11.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.14</td>\n",
       "      <td>10.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.06</td>\n",
       "      <td>13.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.00</td>\n",
       "      <td>11.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.55</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.95</td>\n",
       "      <td>10.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.64</td>\n",
       "      <td>5.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.00</td>\n",
       "      <td>6.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.80</td>\n",
       "      <td>5.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.31</td>\n",
       "      <td>7.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.81</td>\n",
       "      <td>14.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.00</td>\n",
       "      <td>12.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.60</td>\n",
       "      <td>7.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.50</td>\n",
       "      <td>13.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1      2      3      4      5      6      7      8      9    ...  \\\n",
       "0    3.18  15.08   0.00   0.00  19.50   4.83   0.00  17.84   7.21  14.01  ...   \n",
       "1   19.79  10.71   0.00  19.35  15.61   7.46   0.00  14.16   7.46  16.15  ...   \n",
       "2    1.34  17.36   0.00   0.00   6.83  11.44   0.00  20.17   1.58  16.15  ...   \n",
       "3    2.84  15.37   0.00   0.00   5.61   2.50   0.00   4.79   4.11  14.01  ...   \n",
       "4    3.48   8.62  20.03  12.80  12.36   3.91  19.59   2.84   2.26  17.41  ...   \n",
       "..    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  ...   \n",
       "95   0.00   8.86   0.00   0.00  12.55   7.65  13.33   7.65  10.71   0.00  ...   \n",
       "96   5.37  14.06   0.00   0.00  14.11  11.05   0.00  13.14  10.71   0.00  ...   \n",
       "97   0.00  11.34   0.00   0.00  17.55   1.92   0.00  10.95  10.71   0.00  ...   \n",
       "98   0.00   6.68   0.00   0.00  12.80   5.95   0.00  12.31   7.60   0.00  ...   \n",
       "99   0.00  12.07   0.00   0.00  12.60   7.55   0.00  11.00   6.05   0.00  ...   \n",
       "\n",
       "      990    991    992    993    994    995    996    997   998    999  \n",
       "0    0.00  13.38  13.09   0.00  14.54  12.94  15.27  16.58  3.67   9.88  \n",
       "1    0.00  20.27   7.17   0.00  16.83   5.47  11.39  16.63  4.45  11.73  \n",
       "2    0.00  13.57   9.16   0.00   8.38  16.19  16.39  15.85  3.67   9.16  \n",
       "3    0.00   9.98   8.62   0.00  13.57   5.51   5.37   7.89  3.67   9.50  \n",
       "4   12.07   2.02   7.65  13.96  17.84   6.92   7.41  14.40  9.40  13.52  \n",
       "..    ...    ...    ...    ...    ...    ...    ...    ...   ...    ...  \n",
       "95   0.00   0.00   0.00   0.00  19.06   6.87   0.00   0.00  3.77   0.00  \n",
       "96   0.00   0.00   0.00   0.00  19.06  13.23   0.00   0.00  3.77   0.00  \n",
       "97   0.00   0.00   0.00   0.00  14.64   5.47   0.00   0.00  3.77   0.00  \n",
       "98   0.00  20.03   0.00   0.00  10.81  14.54   0.00   0.00  3.77   0.00  \n",
       "99   0.00   0.00   0.00   0.00  14.50  13.38   0.00   0.00  3.28   0.00  \n",
       "\n",
       "[100 rows x 1000 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_ratings = user_ratings.T\n",
    "joke_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 1000), (20, 1000), (80, 1), (20, 1))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(joke_ratings, jokes, test_size=0.2, random_state=33)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the training component, item-item similarities for all pairs of items are computed and stored in an appropriate data structure. Your training function should be able to use different similarity functions(passed as parameter) including Cosine Similarity or Pearson Correlation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(DT, measure):\n",
    "    similarity = []\n",
    "    for i in range(len(DT)):\n",
    "        for j in range(i, len(DT)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if measure == 0:\n",
    "                # cosine similarity\n",
    "                metric=cos_sim\n",
    "                s = metric(DT[i], DT[j])\n",
    "                joke = (s, i, j)\n",
    "                similarity.append(joke)\n",
    "            elif measure == 1:\n",
    "                # pearson correlation\n",
    "                metric=pearsonSim\n",
    "                s = metric(DT[i], DT[j])\n",
    "                joke = (s, i, j)\n",
    "                similarity.append(joke)\n",
    "    similarity.sort(reverse=True)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5876861916332177, 68, 76),\n",
       " (0.583665862135532, 68, 78),\n",
       " (0.5535455160004851, 1, 52),\n",
       " (0.5449474548041287, 14, 68),\n",
       " (0.5444632796658321, 35, 76)]"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosine similarity\n",
    "c_similarity = training(X_train, 0)\n",
    "c_similarity[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9366996388217678, 60, 67),\n",
       " (0.9281184407526155, 36, 67),\n",
       " (0.9211802501682792, 9, 60),\n",
       " (0.9192813981299488, 9, 67),\n",
       " (0.9107610183340304, 36, 60)]"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perarson correlation \n",
    "p_similarity = training(X_train, 1)\n",
    "p_similarity[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Prediction function should take as parameters a target user, an item, a value of k, and the similarities data structure and return the predicted rating on the target item for the target user:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(target, item, k, similarity):\n",
    "    sims = []\n",
    "    for i in range(len(similarity)):\n",
    "        if (similarity[i][1] == item) or (similarity[i][2] == item):\n",
    "            sims.append(similarity[i])          \n",
    "    k_sims = sims[:k]\n",
    "    #print(k_sims)\n",
    "    \n",
    "    k_most = []\n",
    "    for i in range(len(k_sims)):\n",
    "        if k_sims[i][1]!= item:\n",
    "            k_most.append(k_sims[i][1])\n",
    "        else:\n",
    "            k_most.append(k_sims[i][2])\n",
    "    #print(\"kmost:\",k_most)\n",
    "    \n",
    "    ratings = []\n",
    "    for i in k_most:\n",
    "        r = user_ratings[target][i]\n",
    "        ratings.append(r)\n",
    "    avg_ratings = np.mean(ratings)   \n",
    "    #print(\"r:\",ratings)\n",
    "    \n",
    "    return avg_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Cosine similarity\n",
      "Prediction: 7.32\n",
      "Actual: 2.07\n"
     ]
    }
   ],
   "source": [
    "target = 15\n",
    "item = 5\n",
    "k = 5\n",
    "pred1 = predict(target, item, k, c_similarity)\n",
    "print(\"Using Cosine similarity\")\n",
    "print(\"Prediction:\", pred1)\n",
    "print(\"Actual:\",user_ratings[target][item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pearson Correlation\n",
      "Prediction: 6.332000000000001\n",
      "Actual: 2.07\n"
     ]
    }
   ],
   "source": [
    "target = 15\n",
    "item = 5\n",
    "k = 5\n",
    "pred2 = predict(target, item, k, p_similarity)\n",
    "print(\"Using Pearson Correlation\")\n",
    "print(\"Prediction:\", pred2)\n",
    "print(\"Actual:\",user_ratings[target][item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You should test the prediction accuracy of your estimation function (using cross-validation similar to part b above):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pearson Correlation \n",
    "estimation = []\n",
    "for i in range(1, 40):\n",
    "    estimation.append(predict(target, item, i, p_similarity))\n",
    "#estimation[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = []\n",
    "for i in range(len(estimation)):\n",
    "    err.append(abs(estimation[i] - user_ratings[target][item]))    \n",
    "#err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_err = min(err)\n",
    "best_k = err.index(min_err)\n",
    "best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1425000000000005"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err[best_k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Provide a plot of cross-validation accuracies across a range of values of k:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd6191c9690>]"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.figure(figsize=(8,5))\n",
    "pl.xlabel(\"Values of K\")\n",
    "pl.ylabel(\"Cross validation MAE\")\n",
    "pl.plot(err)\n",
    "plt.plot(best_k, err[best_k],'rd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the best value of k, demonstrate the functionality of your recommender by generating recommendations for several anecdotal users:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User  22\n",
      "Prediction: 12.243333333333332\n",
      "Actual: 10.71\n",
      "--------------------------------------------------\n",
      "User  45\n",
      "Prediction: 7.376666666666666\n",
      "Actual: 17.84\n",
      "--------------------------------------------------\n",
      "User  68\n",
      "Prediction: 9.283333333333333\n",
      "Actual: 11.73\n",
      "--------------------------------------------------\n",
      "User  89\n",
      "Prediction: 3.546666666666667\n",
      "Actual: 6.29\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# User A\n",
    "target = 22\n",
    "item = 8\n",
    "pred = predict(target, item, 3, p_similarity)\n",
    "print(\"User \", target)\n",
    "print(\"Prediction:\", pred)\n",
    "print(\"Actual:\",user_ratings[target][item])\n",
    "print(\"-\"*50)\n",
    "\n",
    "# User B\n",
    "target = 45\n",
    "item = 3\n",
    "pred = predict(target, item, best_k, p_similarity)\n",
    "print(\"User \", target)\n",
    "print(\"Prediction:\", pred)\n",
    "print(\"Actual:\",user_ratings[target][item])\n",
    "print(\"-\"*50)\n",
    "\n",
    "# User C\n",
    "target = 68\n",
    "item = 42\n",
    "pred = predict(target, item, best_k, p_similarity)\n",
    "print(\"User \", target)\n",
    "print(\"Prediction:\", pred)\n",
    "print(\"Actual:\",user_ratings[target][item])\n",
    "print(\"-\"*50)\n",
    "\n",
    "# User D\n",
    "target = 89\n",
    "item = 5\n",
    "pred = predict(target, item, best_k, p_similarity)\n",
    "print(\"User \", target)\n",
    "print(\"Prediction:\", pred)\n",
    "print(\"Actual:\",user_ratings[target][item])\n",
    "print(\"-\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
